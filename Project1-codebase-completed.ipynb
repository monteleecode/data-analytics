{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "105e5337-90fc-423c-917f-cbc40834f2c5",
   "metadata": {},
   "source": [
    "## Step 0: Understand the Data\n",
    "Get the info of errors and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0042fd1-fce7-4ca2-90e2-2b545e7cb2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kurti\\AppData\\Local\\Temp\\ipykernel_1468\\1985055591.py:3: DtypeWarning: Columns (0: LSTREET2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  s = pd.read_csv(\"Public_School_Characteristics_2022-23.csv\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(101390, 77)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "s = pd.read_csv(\"Public_School_Characteristics_2022-23.csv\")\n",
    "s_b = s.copy()\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63beb45e-60c1-48d1-b07b-2cfa262b6efc",
   "metadata": {},
   "source": [
    "### Pattern for each column\n",
    "TOTAL = TOTMENROL + TOTFENROL\n",
    "TOTAL = PK + KG + G01 + G02 + G03 + G04 + G05\n",
    "      + G06 + G07 + G08\n",
    "      + G09 + G10 + G11 + G12\n",
    "      + UG + AE\n",
    "      \n",
    "TOTAL = AM + AS + HI + BL + WH + HP + TR\n",
    "\n",
    "Lunch:\n",
    "TOTFRL = FRELCH + REDLCH\n",
    "\n",
    "STUTERATIO = TOTAL / FTE\n",
    "\n",
    "Elementary Schools:\n",
    "G09 + G10 + G11 + G12 ≈ 0\n",
    "\n",
    "High Schools:\n",
    "PK + KG + G01–G08 ≈ 0\n",
    "\n",
    "AMALM + AMALF = AM\n",
    "\n",
    "ASALM + ASALF = AS\n",
    "\n",
    "BLALM + BLALF = BL\n",
    "\n",
    "HPALM + HPALF = HP\n",
    "\n",
    "HIALM + HIALF = HI\n",
    "\n",
    "TRALM + TRALF = TR\n",
    "\n",
    "WHALM + WHALF = WH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42acecb7-7297-4772-af85-11a604f4e683",
   "metadata": {},
   "source": [
    "### Missing Value info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cd82e03-da69-4216-b044-7530ebb00b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62134\n",
      "101390\n",
      "1352278\n"
     ]
    }
   ],
   "source": [
    "special_values = [-1, -2, -9, \"M\", \"N\"]\n",
    "s = s.replace(r'^\\s*$', np.nan, regex=True) # Find any string that is completely empty ('') or only spaces (' '), replace it with np.nan\n",
    "\n",
    "rows_with_special = s.isin(special_values).any(axis=1).sum()\n",
    "print(rows_with_special)\n",
    "rows_with_missing_value = s.isna().any(axis=1).sum()\n",
    "print(rows_with_missing_value)\n",
    "total_missing = s.isna().sum().sum()\n",
    "print(total_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea2d878-c3cd-4a1a-9927-7f4c3ed80a86",
   "metadata": {},
   "source": [
    "## Step 1: Data Cleaning\n",
    "### 1.1 Handling missing 0's for Students Each Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd7edc85-7755-41d2-a205-469476202e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101244\n",
      "238819\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cols = s.loc[:, 'PK':'AE'].columns  # all columns from PK to AE\n",
    "\n",
    "# 1️⃣ Row-wise sum of PK to AE (ignores NaN by default)\n",
    "row_sum = s[cols].sum(axis=1)\n",
    "\n",
    "# 2️⃣ Find rows where sum equals TOTAL\n",
    "mask = row_sum.eq(s['TOTAL'])\n",
    "\n",
    "# 3️⃣ Fill NaN with 0 only for those rows\n",
    "s.loc[mask, cols] = s.loc[mask, cols].fillna(0)\n",
    "print(s.isna().any(axis=1).sum())\n",
    "print(s.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c6b271-c824-4f16-88cc-4a89c9fd4459",
   "metadata": {},
   "source": [
    "### 2.2 Removing Redundant Rows and Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ec4995-7a04-4674-83c3-d98b40215880",
   "metadata": {},
   "source": [
    "#### Dropping Rows and Features with Too less value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff9b0643-1643-48b6-b765-341a13352c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49    0.181818\n",
       "50    0.571429\n",
       "51    0.571429\n",
       "52    0.571429\n",
       "53    0.571429\n",
       "54    0.571429\n",
       "55    0.571429\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reference for rows missing value threshold\n",
    "s_b.loc[49:55,:].isna().mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d4a968e-13e6-41cb-9be7-eb74551caef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99577\n",
      "164969\n",
      "LSTREET2          99215\n",
      "LZIP4             41866\n",
      "FTE                2565\n",
      "STUTERATIO         1814\n",
      "HPALM               941\n",
      "                  ...  \n",
      "SY_STATUS_TEXT        0\n",
      "ULOCALE               0\n",
      "NMCNTY                0\n",
      "LATCOD                0\n",
      "LONCOD                0\n",
      "Length: 77, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "s = s[s.isna().mean(axis=1) <= 0.55]\n",
    "print(s.isna().any(axis=1).sum())\n",
    "print(s.isna().sum().sum())\n",
    "print(s.isna().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "630db254-4478-4115-9e87-affacebc9306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5403\n",
      "23888\n",
      "60467\n"
     ]
    }
   ],
   "source": [
    "s = s.loc[:, s.isna().mean() <= 0.40]\n",
    "print(s.isna().any(axis=1).sum())\n",
    "print(s.isna().sum().sum())\n",
    "print(s.isin(special_values).any(axis=1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b597ac7-e67a-4490-895c-2189f1d647ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.to_csv(\"Deliverable2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a4f1b7-7cf8-4e32-a5a3-d90e2c7ba2c2",
   "metadata": {},
   "source": [
    "### 2.3 Imputate Continuous Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cbc4c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing counts (after placeholder -> NaN):\n",
      "DIRECTCERT    49548\n",
      "FRELCH        18960\n",
      "REDLCH        18960\n",
      "TOTFRL        13098\n",
      "STUTERATIO     4383\n",
      "FTE            2565\n",
      "TOTAL             4\n",
      "dtype: int64\n",
      "Filled TOTAL from grade sums: 4\n",
      "mean abs diff = 0.0063\n",
      "Filled STUTERATIO values: 0\n",
      "Filled FTE values: 0\n",
      "\n",
      "Missing counts after continuous imputations:\n",
      "TOTAL          4\n",
      "FTE            4\n",
      "STUTERATIO    55\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# NCES placeholder codes (-1, -2, -9) are non observations (missing / not applicable / low quality),\n",
    "# so they shouldn't be used as real numeric values in statistics and be replaced.\n",
    "\n",
    "placeholder_codes = [-1, -2, -9, \"M\", \"N\"]\n",
    "\n",
    "# Replace placeholder codes with NaN (only for columns where codes appear)\n",
    "for c in [\"STUTERATIO\", \"TOTFRL\", \"FRELCH\", \"REDLCH\", \"DIRECTCERT\"]:\n",
    "    if c in s.columns:\n",
    "        s[c] = s[c].replace(placeholder_codes, np.nan)\n",
    "\n",
    "# Ensure numeric columns are numeric\n",
    "numeric_fix_cols = [\n",
    "    \"TOTAL\", \"FTE\", \"STUTERATIO\",\n",
    "    \"TOTFRL\", \"FRELCH\", \"REDLCH\", \"DIRECTCERT\"\n",
    "]\n",
    "for c in numeric_fix_cols:\n",
    "    if c in s.columns:\n",
    "        s[c] = pd.to_numeric(s[c], errors=\"coerce\")\n",
    "\n",
    "print(\"Missing counts (after placeholder -> NaN):\")\n",
    "print(s[numeric_fix_cols].isna().sum().sort_values(ascending=False))\n",
    "\n",
    "# TOTAL: If TOTAL is missing, rebuild from grade level columns (PK to AE) when possible.\n",
    "grade_cols = [c for c in s.columns if c in list(s.loc[:, \"PK\":\"AE\"].columns)]\n",
    "if \"TOTAL\" in s.columns and grade_cols:\n",
    "    total_from_grades = s[grade_cols].sum(axis=1, min_count=1)\n",
    "    missing_total = s[\"TOTAL\"].isna()\n",
    "    s.loc[missing_total, \"TOTAL\"] = total_from_grades[missing_total]\n",
    "    print(\"Filled TOTAL from grade sums:\", int(missing_total.sum()))\n",
    "\n",
    "# STUTERATIO: If missing, compute using TOTAL and FTE when both exist.\n",
    "# First, we check that the relationship holds for most records.\n",
    "if \"TOTAL\" in s.columns and \"FTE\" in s.columns and \"STUTERATIO\" in s.columns:\n",
    "    s[\"RATIO_FROM_TOTAL_FTE\"] = s[\"TOTAL\"] / s[\"FTE\"]\n",
    "    s.loc[s[\"FTE\"] == 0, \"RATIO_FROM_TOTAL_FTE\"] = None\n",
    "    temp = s.dropna(subset=[\"STUTERATIO\", \"RATIO_FROM_TOTAL_FTE\"])\n",
    "    temp[\"ABS_DIFF\"] = (temp[\"STUTERATIO\"] - temp[\"RATIO_FROM_TOTAL_FTE\"]).abs()\n",
    "    print(\"mean abs diff =\", round(float(temp[\"ABS_DIFF\"].mean()), 4))\n",
    "    before = s[\"STUTERATIO\"].isna().sum()\n",
    "    s.loc[s[\"STUTERATIO\"].isna(), \"STUTERATIO\"] = s[\"RATIO_FROM_TOTAL_FTE\"]\n",
    "    after = s[\"STUTERATIO\"].isna().sum()\n",
    "    print(\"Filled STUTERATIO values:\", int(before - after))\n",
    "    s = s.drop(columns=[\"RATIO_FROM_TOTAL_FTE\"], errors=\"ignore\")\n",
    "# To verify consistency internally, we compared the STUTERATIO to the computed value TOTAL/FTE. \n",
    "# We calculated the mean absolute difference to measure the avg deviation between the two values. \n",
    "# A small mean absolute difference shows that the ratios are consistent with actual enrollment and teacher counts.\n",
    "\n",
    "# FTE: If missing, compute using TOTAL / STUTERATIO.\n",
    "if \"TOTAL\" in s.columns and \"FTE\" in s.columns and \"STUTERATIO\" in s.columns:\n",
    "    s[\"FTE_FROM_RATIO\"] = s[\"TOTAL\"] / s[\"STUTERATIO\"]\n",
    "    s.loc[s[\"STUTERATIO\"] == 0, \"FTE_FROM_RATIO\"] = None\n",
    "    before = s[\"FTE\"].isna().sum()\n",
    "    s.loc[s[\"FTE\"].isna(), \"FTE\"] = s[\"FTE_FROM_RATIO\"]\n",
    "    after = s[\"FTE\"].isna().sum()\n",
    "    print(\"Filled FTE values:\", int(before - after))\n",
    "    s = s.drop(columns=[\"FTE_FROM_RATIO\"], errors=\"ignore\")\n",
    "\n",
    "# Remaining missing in continuous columns: use group wise median since less sensitive to outliers\n",
    "# Group by SCHOOL_LEVEL and STABR if available because school staffing and enrollment patterns are different depending on level and state.\n",
    "for c in [\"STUTERATIO\", \"FTE\"]:\n",
    "    if c in s.columns:\n",
    "        # If both grouping columns exist, fill by SCHOOL_LEVEL and STABR\n",
    "        if \"SCHOOL_LEVEL\" in s.columns and \"STABR\" in s.columns:\n",
    "            for level in s[\"SCHOOL_LEVEL\"].dropna().unique():\n",
    "                for state in s[\"STABR\"].dropna().unique():\n",
    "                    # rows in this level and this state\n",
    "                    condition = (s[\"SCHOOL_LEVEL\"] == level) & (s[\"STABR\"] == state)\n",
    "                    group_values = s.loc[condition, c]\n",
    "                    # calculate median if the group has at least one proper value\n",
    "                    if group_values.notna().sum() > 0:\n",
    "                        group_median = group_values.median()\n",
    "                        # fill only missing values inside this group\n",
    "                        s.loc[condition & s[c].isna(), c] = group_median\n",
    "        # Otherwise, fill it with overall median\n",
    "        else:\n",
    "            overall_median = s[c].median()\n",
    "            s.loc[s[c].isna(), c] = overall_median\n",
    "# Remaining missing values in continuous variables (STUTERATIO and FTE) were imputed using group-wise median imputation. \n",
    "# Schools were grouped by SCHOOL_LEVEL and STABR because staffing and enrollment differ across different school types and states. \n",
    "# Median was chosen instead of mean to minimize sensitivity to extreme outliers in the enrollment and staffing counters. \n",
    "# This helps to uphold differences in the structure of the dataset but preventing too much data loss from deleting rows. \n",
    "# If grouping variables were unavailable, overall median imputation was used.\n",
    "\n",
    "print(\"\\nMissing counts after continuous imputations:\")\n",
    "print(s[[\"TOTAL\", \"FTE\", \"STUTERATIO\"]].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e163744b-1eaa-445c-8e83-844c0ba72a4f",
   "metadata": {},
   "source": [
    "### 2.4 Imputate Discrete Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4e01aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done discrete repairs. Remaining missing values (top 15):\n",
      "DIRECTCERT    49548\n",
      "HPALM           941\n",
      "HPALF           940\n",
      "AMALM           914\n",
      "AMALF           912\n",
      "HP              894\n",
      "AM              866\n",
      "BLALF           830\n",
      "BLALM           827\n",
      "ASALM           825\n",
      "ASALF           823\n",
      "BL              820\n",
      "TRALM           820\n",
      "TRALF           818\n",
      "TR              817\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Fix postal codes: if LZIP is numeric, leading zeros are lost in python. This converts them back to 5 character string.\n",
    "if \"LZIP\" in s.columns:\n",
    "    s[\"LZIP\"] = s[\"LZIP\"].astype(\"Int64\").astype(str).str.zfill(5)\n",
    "\n",
    "# Address field: if missing, fill with 'Unknown'\n",
    "for c in [\"LSTREET1\", \"PHONE\"]:\n",
    "    if c in s.columns:\n",
    "        s[c] = s[c].fillna(\"Unknown\")\n",
    "# Missing values in categorical variables not included in the analysis such as street address and phone number were replaced \n",
    "# with the placeholder value \"Unknown\". These variables are descriptive identifiers and are not used for analysis. \n",
    "# Replacing missing values prevents needing to delete rows unnecessarily due to empty values and ensures consistency in the dataset.\n",
    "\n",
    "# Free/Reduced lunch fields: these are count fields and can be 0 for schools with no participants.\n",
    "# We used enrollment percentage as a consideration to avoid producing impossible counts.\n",
    "if \"TOTFRL\" in s.columns and \"TOTAL\" in s.columns:\n",
    "    # Create FRL_PCT (only when TOTAL > 0)\n",
    "    s[\"FRL_PCT\"] = s[\"TOTFRL\"] / s[\"TOTAL\"]\n",
    "    s.loc[s[\"TOTAL\"] == 0, \"FRL_PCT\"] = None\n",
    "    # Fill missing FRL_PCT with overall median\n",
    "    frl_median = s[\"FRL_PCT\"].median()\n",
    "    s.loc[s[\"FRL_PCT\"].isna(), \"FRL_PCT\"] = frl_median\n",
    "    # missing TOTFRL using FRL_PCT * TOTAL\n",
    "    s.loc[s[\"TOTFRL\"].isna(), \"TOTFRL\"] = (s[\"FRL_PCT\"] * s[\"TOTAL\"]).round()\n",
    "    # keep TOTFRL within valid range [0, TOTAL]\n",
    "    s.loc[s[\"TOTFRL\"] < 0, \"TOTFRL\"] = 0\n",
    "    s.loc[s[\"TOTFRL\"] > s[\"TOTAL\"], \"TOTFRL\"] = s[\"TOTAL\"]\n",
    "# if FRELCH and REDLCH exist, fill missing by splitting TOTFRL 50/50\n",
    "if \"FRELCH\" in s.columns and \"REDLCH\" in s.columns and \"TOTFRL\" in s.columns:\n",
    "    # If missing, assign half of TOTFRL to free lunch\n",
    "    s.loc[s[\"FRELCH\"].isna(), \"FRELCH\"] = (0.5 * s[\"TOTFRL\"]).round()\n",
    "    # Reduced lunch is whatever is left\n",
    "    s.loc[s[\"REDLCH\"].isna(), \"REDLCH\"] = (s[\"TOTFRL\"] - s[\"FRELCH\"]).round()\n",
    "    # Prevent negatives\n",
    "    s.loc[s[\"REDLCH\"] < 0, \"REDLCH\"] = 0\n",
    "# The Free/Reduced Lunch variables are count fields, so they must be not negative and not greater than total enrollment.\n",
    "# To handle missing values first, we converted the total FRL count into a percentage of enrollment so that any imputed values \n",
    "# would scale properly with school size. Missing percentages were filled using the median to avoid being influenced by extreme values. \n",
    "# Then we rebuilt missing FRL counts using the percentage and total enrollment, rounding to keep whole numbers. \n",
    "# More checks made sure values stayed between 0 and total enrollment. When the free and reduced breakdown was missing,\n",
    "# we used a 50/50 split to maintain consistency. These steps ensured logical modification while keeping as much data as possible.\n",
    "\n",
    "# Ensure counts are non-negative\n",
    "count_cols = [\"TOTAL\", \"TOTFRL\", \"FRELCH\", \"REDLCH\", \"DIRECTCERT\", \"TOTMENROL\", \"TOTFENROL\", \"MEMBER\"]\n",
    "\n",
    "for c in count_cols:\n",
    "    if c in s.columns:\n",
    "        s[c] = pd.to_numeric(s[c], errors=\"coerce\")\n",
    "        s.loc[s[c] < 0, c] = 0\n",
    "\n",
    "print(\"Done discrete repairs. Remaining missing values (top 15):\")\n",
    "print(s.isna().sum().sort_values(ascending=False).head(15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0466692-4de6-4097-9e71-1df3cfabff92",
   "metadata": {},
   "source": [
    "### 2.5 Handling Edge Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fab8960d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with all race counts missing: 813\n",
      "Rows where race sum exceeds TOTAL (dropped): 0\n",
      "Rows where male+female != TOTAL: 5978\n",
      "\n",
      "Remaining missing values (top 15):\n",
      "DIRECTCERT    49527\n",
      "HPALM           128\n",
      "HPALF           127\n",
      "AMALM           101\n",
      "AMALF            99\n",
      "STUTERATIO       49\n",
      "HP               31\n",
      "AM               27\n",
      "BLALF            17\n",
      "BLALM            14\n",
      "ASALM            12\n",
      "ASALF            10\n",
      "TRALM             7\n",
      "BL                6\n",
      "UG                5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Goal: ensure totals are internally consistent and remove/repair impossible records. Sorry Monte partially gave up on this section LOL\n",
    "\n",
    "race_cols = [\"AM\",\"AS\",\"BL\",\"HI\",\"HP\",\"TR\",\"WH\"]\n",
    "race_cols = [c for c in race_cols if c in s.columns]\n",
    "\n",
    "# Convert to numeric\n",
    "for c in race_cols:\n",
    "    s[c] = pd.to_numeric(s[c], errors=\"coerce\")\n",
    "\n",
    "# Race counts: if ALL race columns are missing, ethnicity composition cannot be computed.\n",
    "# Since our problem statement uses ethnicity composition, we drop these rows.\n",
    "all_race_missing = s[race_cols].isna().all(axis=1) if len(race_cols) > 0 else pd.Series(False, index=s.index)\n",
    "print(\"Rows with all race counts missing:\", int(all_race_missing.sum()))\n",
    "s = s.loc[~all_race_missing].copy()\n",
    "\n",
    "# If some race categories are missing but the known categories already sum to TOTAL, then missing categories must be 0.\n",
    "if \"TOTAL\" in s.columns:\n",
    "\n",
    "    race_sum_known = s[race_cols].sum(axis=1, min_count=1)\n",
    "\n",
    "    # Loop through each row\n",
    "    race_na_any = s[race_cols].isna().any(axis=1)\n",
    "    for i in s.index:\n",
    "        if (race_na_any.at[i] and pd.notna(s.at[i, \"TOTAL\"]) and race_sum_known.at[i] == s.at[i, \"TOTAL\"]):\n",
    "            s.loc[i, race_cols] = s.loc[i, race_cols].fillna(0)\n",
    "\n",
    "    # If exactly ONE race category is missing and TOTAL is known, fill the missing one as the remainder.\n",
    "    missing_counts = s[race_cols].isna().sum(axis=1)\n",
    "    one_missing = (missing_counts == 1) & s[\"TOTAL\"].notna()\n",
    "    remainder = s[\"TOTAL\"] - s[race_cols].sum(axis=1, min_count=1)\n",
    "\n",
    "    # Identify which column is missing per row and fill it\n",
    "    for c in race_cols:\n",
    "        mask = one_missing & s[c].isna() & (remainder >= 0)\n",
    "        s.loc[mask, c] = remainder[mask]\n",
    "\n",
    "    # Any remaining negative remainder means race totals exceed TOTAL (inconsistent).\n",
    "    remainder_after = s[\"TOTAL\"] - s[race_cols].sum(axis=1, min_count=1)\n",
    "    inconsistent_race = remainder_after < 0\n",
    "    print(\"Rows where race sum exceeds TOTAL (dropped):\", int(inconsistent_race.sum()))\n",
    "    s = s.loc[~inconsistent_race].copy()\n",
    "\n",
    "# Gender totals vs TOTAL: if TOTMENROL + TOTFENROL != TOTAL, we keep as is but flag for awareness.\n",
    "if \"TOTMENROL\" in s.columns and \"TOTFENROL\" in s.columns and \"TOTAL\" in s.columns:\n",
    "    condition = (s[\"TOTMENROL\"].notna() & s[\"TOTFENROL\"].notna() & s[\"TOTAL\"].notna())\n",
    "    # Among those rows, check if male + female does NOT equal TOTAL\n",
    "    inconsistent = s.loc[condition, \"TOTMENROL\"] + s.loc[condition, \"TOTFENROL\"] != s.loc[condition, \"TOTAL\"]\n",
    "    print(\"Rows where male+female != TOTAL:\", int(inconsistent.sum()))\n",
    "    \n",
    "# Final missing snapshot\n",
    "print(\"\\nRemaining missing values (top 15):\")\n",
    "print(s.isna().sum().sort_values(ascending=False).head(15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cea250-0a98-475e-a627-33d2d6ddf55b",
   "metadata": {},
   "source": [
    "### 2.6 Feature Engineering\n",
    "The features added through the imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f6779b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example engineered columns:\n",
      "['FRL_PCT', 'AM_PCT', 'AS_PCT', 'BL_PCT', 'HI_PCT', 'HP_PCT', 'TR_PCT', 'WH_PCT', 'MINORITY_PCT', 'MINORITY_PCT', 'FRL_PCT', 'SCHOOL_LEVEL_CODE']\n"
     ]
    }
   ],
   "source": [
    "# Ethnicity composition as proportions (robust to different school sizes)\n",
    "race_cols = [\"AM\",\"AS\",\"BL\",\"HI\",\"HP\",\"TR\",\"WH\"]\n",
    "race_cols = [c for c in race_cols if c in s.columns]\n",
    "\n",
    "for c in race_cols:\n",
    "    s[c] = pd.to_numeric(s[c], errors=\"coerce\")\n",
    "\n",
    "if \"TOTAL\" in s.columns:\n",
    "    for c in race_cols:\n",
    "        s[f\"{c}_PCT\"] = np.where(s[\"TOTAL\"] > 0, s[c] / s[\"TOTAL\"], np.nan)\n",
    "\n",
    "    # minority share (everything except White)\n",
    "    if \"WH\" in s.columns:\n",
    "        s[\"MINORITY_PCT\"] = 1 - s[\"WH_PCT\"]\n",
    "\n",
    "# School level (ordinal encoding) to support correlation\n",
    "level_map = {\n",
    "    \"Primary\": 1,\n",
    "    \"Middle\": 2,\n",
    "    \"High\": 3,\n",
    "    \"Other\": 0\n",
    "}\n",
    "if \"SCHOOL_LEVEL\" in s.columns:\n",
    "    s[\"SCHOOL_LEVEL_CODE\"] = s[\"SCHOOL_LEVEL\"].map(level_map).fillna(0).astype(int)\n",
    "\n",
    "print(\"Example engineered columns:\")\n",
    "engineered_cols = [c for c in s.columns if c.endswith(\"_PCT\")] + [\"MINORITY_PCT\",\"FRL_PCT\",\"IS_CHARTER\",\"IS_VIRTUAL\",\"SCHOOL_LEVEL_CODE\"]\n",
    "print([c for c in engineered_cols if c in s.columns][:20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8044204f-9b9e-4fc9-b440-f5f241045095",
   "metadata": {},
   "source": [
    "### 2.7 Dropping Constant Features and Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2f03383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant columns: ['SURVYEAR']\n",
      ">=99.5% same: ['SURVYEAR', 'G13', 'AE']\n",
      "Exact duplicate rows removed: 0\n",
      "Duplicate NCESSCH rows removed: 0\n"
     ]
    }
   ],
   "source": [
    "# Drop fully-constant columns providing no information for model\n",
    "nunique = s.nunique(dropna=False)\n",
    "constant_cols = list(nunique[nunique <= 1].index)\n",
    "print(\"Constant columns:\", constant_cols)\n",
    "\n",
    "# >= 99.5% of rows share the same value\n",
    "quasi_constant_cols = []\n",
    "for col in s.columns:\n",
    "    top_freq = s[col].value_counts(dropna=False, normalize=True).iloc[0]\n",
    "    if top_freq >= 0.995:\n",
    "        quasi_constant_cols.append(col)\n",
    "\n",
    "print(\">=99.5% same:\", quasi_constant_cols)\n",
    "\n",
    "# Remove duplicate records (exact duplicates or duplicate school IDs)\n",
    "before = s.shape[0]\n",
    "s = s.drop_duplicates()\n",
    "after = s.shape[0]\n",
    "print(f\"Exact duplicate rows removed: {before-after}\")\n",
    "\n",
    "if \"NCESSCH\" in s.columns:\n",
    "    before = s.shape[0]\n",
    "    s = s.drop_duplicates(subset=[\"NCESSCH\"])\n",
    "    after = s.shape[0]\n",
    "    print(f\"Duplicate NCESSCH rows removed: {before-after}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8986a41d-dcc4-47b7-a92b-cc912f84b787",
   "metadata": {},
   "source": [
    "### 2.8 Data Shape After Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "744aa415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after cleaning: (98910, 85)\n",
      "Total missing values remaining: 72232\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape after cleaning:\", s.shape)\n",
    "print(\"Total missing values remaining:\", int(s.isna().sum().sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb0d7b1-d112-4e49-ae54-317cf52848c1",
   "metadata": {},
   "source": [
    "## Step 3: Normalization and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f294a441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.8-cp312-cp312-win_amd64.whl.metadata (52 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.3-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.61.1-cp312-cp312-win_amd64.whl.metadata (116 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\kurti\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (2.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kurti\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-12.1.1-cp312-cp312-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Downloading pyparsing-3.3.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kurti\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kurti\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.8-cp312-cp312-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   --------------------------------- ------ 6.8/8.1 MB 38.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 36.0 MB/s  0:00:00\n",
      "Downloading contourpy-1.3.3-cp312-cp312-win_amd64.whl (226 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.61.1-cp312-cp312-win_amd64.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.3/2.3 MB 66.4 MB/s  0:00:00\n",
      "Downloading kiwisolver-1.4.9-cp312-cp312-win_amd64.whl (73 kB)\n",
      "Downloading pillow-12.1.1-cp312-cp312-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 7.0/7.0 MB 48.4 MB/s  0:00:00\n",
      "Downloading pyparsing-3.3.2-py3-none-any.whl (122 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "\n",
      "   ---------------------------------------- 0/7 [pyparsing]\n",
      "   ---------------------------------------- 0/7 [pyparsing]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ---------------------------- ----------- 5/7 [contourpy]\n",
      "   ---------------------------- ----------- 5/7 [contourpy]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------------- 7/7 [matplotlib]\n",
      "\n",
      "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.61.1 kiwisolver-1.4.9 matplotlib-3.10.8 pillow-12.1.1 pyparsing-3.3.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Transformation (log1p) for heavy-tailed count features to reduce skew\n",
    "\n",
    "# Standardization (z-score) for continuous features used in modeling\n",
    "\n",
    "# Select a few representative count features\n",
    "count_features = [c for c in [\"TOTAL\",\"FTE\",\"TOTFRL\"] if c in s.columns]\n",
    "for c in count_features:\n",
    "    s[f\"LOG1P_{c}\"] = np.log1p(s[c])\n",
    "\n",
    "# Standardize continuous features\n",
    "cont_features = [c for c in [\"STUTERATIO\",\"FRL_PCT\",\"MINORITY_PCT\",\"TOTAL\",\"FTE\"] if c in s.columns]\n",
    "for c in cont_features:\n",
    "    mean = s[c].mean()\n",
    "    std = s[c].std()\n",
    "    s[f\"Z_{c}\"] = (s[c] - mean) / std\n",
    "\n",
    "# Correlation analysis: which engineered variables correlate with STUTERATIO?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c2c7ae",
   "metadata": {},
   "source": [
    "### 3.1 Export Cleaned Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d11da9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Deliverable2_cleaned_final.csv\n"
     ]
    }
   ],
   "source": [
    "s.to_csv(\"Deliverable2_somewhatcleaned.csv\", index=False)\n",
    "print(\"Saved Deliverable2_somewhatcleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff120dcc-2acd-49ab-967e-d60fa240ab34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
