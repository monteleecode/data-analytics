{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "105e5337-90fc-423c-917f-cbc40834f2c5",
   "metadata": {},
   "source": [
    "## Step 0: Understand the Data\n",
    "Get the info of errors and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0042fd1-fce7-4ca2-90e2-2b545e7cb2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in C:\\Users\\kurti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages (2.4.2)\n",
      "Requirement already satisfied: pandas in C:\\Users\\kurti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages (3.0.0)\n",
      "Requirement already satisfied: matplotlib in C:\\Users\\kurti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages (3.10.8)\n",
      "Requirement already satisfied: scikit-learn in C:\\Users\\kurti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages (1.8.0)\n",
      "Requirement already satisfied: seaborn in C:\\Users\\kurti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages (0.13.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in C:\\Users\\kurti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata in C:\\Users\\kurti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in C:\\Users\\kurti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in C:\\Users\\kurti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in C:\\Users\\kurti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in C:\\Users\\kurti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in C:\\Users\\kurti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages (from matplotlib) (26.0)\n",
      "Requirement already satisfied: pillow>=8 in C:\\Users\\kurti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages (from matplotlib) (12.1.1)\n",
      "Requirement already satisfied: pyparsing>=3 in C:\\Users\\kurti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages (from matplotlib) (3.3.2)\n",
      "Requirement already satisfied: scipy>=1.10.0 in C:\\Users\\kurti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages (from scikit-learn) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.3.0 in C:\\Users\\kurti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in C:\\Users\\kurti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in C:\\Users\\kurti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kurti\\AppData\\Local\\Temp\\ipykernel_39292\\3717287760.py:5: DtypeWarning: Columns (0: LSTREET2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  s = pd.read_csv(\"Public_School_Characteristics_2022-23.csv\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(101390, 77)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install numpy pandas matplotlib scikit-learn seaborn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "s = pd.read_csv(\"Public_School_Characteristics_2022-23.csv\")\n",
    "s_b = s.copy()\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63beb45e-60c1-48d1-b07b-2cfa262b6efc",
   "metadata": {},
   "source": [
    "### Pattern for each column\n",
    "TOTAL = TOTMENROL + TOTFENROL\n",
    "TOTAL = PK + KG + G01 + G02 + G03 + G04 + G05\n",
    "      + G06 + G07 + G08\n",
    "      + G09 + G10 + G11 + G12\n",
    "      + UG + AE\n",
    "      \n",
    "TOTAL = AM + AS + HI + BL + WH + HP + TR\n",
    "\n",
    "Lunch:\n",
    "TOTFRL = FRELCH + REDLCH\n",
    "\n",
    "STUTERATIO = TOTAL / FTE\n",
    "\n",
    "Elementary Schools:\n",
    "G09 + G10 + G11 + G12 ≈ 0\n",
    "\n",
    "High Schools:\n",
    "PK + KG + G01–G08 ≈ 0\n",
    "\n",
    "AMALM + AMALF = AM\n",
    "\n",
    "ASALM + ASALF = AS\n",
    "\n",
    "BLALM + BLALF = BL\n",
    "\n",
    "HPALM + HPALF = HP\n",
    "\n",
    "HIALM + HIALF = HI\n",
    "\n",
    "TRALM + TRALF = TR\n",
    "\n",
    "WHALM + WHALF = WH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42acecb7-7297-4772-af85-11a604f4e683",
   "metadata": {},
   "source": [
    "### Missing Value info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cd82e03-da69-4216-b044-7530ebb00b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62134\n",
      "101390\n",
      "1352278\n"
     ]
    }
   ],
   "source": [
    "special_values = [-1, -2, -9, \"M\", \"N\"]\n",
    "s = s.replace(r'^\\s*$', np.nan, regex=True) # Find any string that is completely empty ('') or only spaces (' '), replace it with np.nan\n",
    "\n",
    "rows_with_special = s.isin(special_values).any(axis=1).sum()\n",
    "print(rows_with_special)\n",
    "rows_with_missing_value = s.isna().any(axis=1).sum()\n",
    "print(rows_with_missing_value)\n",
    "total_missing = s.isna().sum().sum()\n",
    "print(total_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea2d878-c3cd-4a1a-9927-7f4c3ed80a86",
   "metadata": {},
   "source": [
    "## Step 1: Data Cleaning\n",
    "### 1.1 Handling missing 0's for Students Each Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd7edc85-7755-41d2-a205-469476202e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101244\n",
      "238819\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cols = s.loc[:, 'PK':'AE'].columns  # all columns from PK to AE\n",
    "\n",
    "# 1️⃣ Row-wise sum of PK to AE (ignores NaN by default)\n",
    "row_sum = s[cols].sum(axis=1)\n",
    "\n",
    "# 2️⃣ Find rows where sum equals TOTAL\n",
    "mask = row_sum.eq(s['TOTAL'])\n",
    "\n",
    "# 3️⃣ Fill NaN with 0 only for those rows\n",
    "s.loc[mask, cols] = s.loc[mask, cols].fillna(0)\n",
    "print(s.isna().any(axis=1).sum())\n",
    "print(s.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c6b271-c824-4f16-88cc-4a89c9fd4459",
   "metadata": {},
   "source": [
    "### 2.2 Removing Redundant Rows and Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ec4995-7a04-4674-83c3-d98b40215880",
   "metadata": {},
   "source": [
    "#### Dropping Rows and Features with Too less value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff9b0643-1643-48b6-b765-341a13352c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference for rows missing value threshold\n",
    "s_b.loc[49:55,:].isna().mean(axis=1)\n",
    "for col in [\"CHARTER_TEXT\", \"STATUS\"]:\n",
    "    if col in s.columns:\n",
    "        s = s.drop(columns=[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d4a968e-13e6-41cb-9be7-eb74551caef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99573\n",
      "164801\n",
      "LSTREET2          99215\n",
      "LZIP4             41866\n",
      "FTE                2565\n",
      "STUTERATIO         1814\n",
      "HPALM               937\n",
      "                  ...  \n",
      "SY_STATUS_TEXT        0\n",
      "TOTAL                 0\n",
      "MEMBER                0\n",
      "LATCOD                0\n",
      "LONCOD                0\n",
      "Length: 75, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "s = s[s.isna().mean(axis=1) <= 0.55]\n",
    "print(s.isna().any(axis=1).sum())\n",
    "print(s.isna().sum().sum())\n",
    "print(s.isna().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "630db254-4478-4115-9e87-affacebc9306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5399\n",
      "23720\n",
      "59288\n"
     ]
    }
   ],
   "source": [
    "s = s.loc[:, s.isna().mean() <= 0.40]\n",
    "print(s.isna().any(axis=1).sum())\n",
    "print(s.isna().sum().sum())\n",
    "print(s.isin(special_values).any(axis=1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b597ac7-e67a-4490-895c-2189f1d647ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.to_csv(\"Deliverable2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a4f1b7-7cf8-4e32-a5a3-d90e2c7ba2c2",
   "metadata": {},
   "source": [
    "### 2.3 Imputate Continuous Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cbc4c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing counts (after placeholder -> NaN):\n",
      "DIRECTCERT    49544\n",
      "FRELCH        18956\n",
      "REDLCH        18956\n",
      "TOTFRL        13094\n",
      "STUTERATIO     4379\n",
      "FTE            2565\n",
      "TOTAL             0\n",
      "dtype: int64\n",
      "Filled TOTAL from grade sums: 0\n",
      "mean abs diff = 0.0063\n",
      "Filled STUTERATIO values: 0\n",
      "Filled FTE values: 0\n",
      "\n",
      "Missing counts after continuous imputations:\n",
      "TOTAL          0\n",
      "FTE            4\n",
      "STUTERATIO    51\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# NCES placeholder codes (-1, -2, -9) are non observations (missing / not applicable / low quality),\n",
    "# so they shouldn't be used as real numeric values in statistics and be replaced.\n",
    "\n",
    "placeholder_codes = [-1, -2, -9, \"M\", \"N\"]\n",
    "\n",
    "# Replace placeholder codes with NaN (only for columns where codes appear)\n",
    "for c in [\"STUTERATIO\", \"TOTFRL\", \"FRELCH\", \"REDLCH\", \"DIRECTCERT\"]:\n",
    "    if c in s.columns:\n",
    "        s[c] = s[c].replace(placeholder_codes, np.nan)\n",
    "\n",
    "# Ensure numeric columns are numeric\n",
    "numeric_fix_cols = [\n",
    "    \"TOTAL\", \"FTE\", \"STUTERATIO\",\n",
    "    \"TOTFRL\", \"FRELCH\", \"REDLCH\", \"DIRECTCERT\"\n",
    "]\n",
    "for c in numeric_fix_cols:\n",
    "    if c in s.columns:\n",
    "        s[c] = pd.to_numeric(s[c], errors=\"coerce\")\n",
    "\n",
    "print(\"Missing counts (after placeholder -> NaN):\")\n",
    "print(s[numeric_fix_cols].isna().sum().sort_values(ascending=False))\n",
    "\n",
    "# TOTAL: If TOTAL is missing, rebuild from grade level columns (PK to AE) when possible.\n",
    "grade_cols = [c for c in s.columns if c in list(s.loc[:, \"PK\":\"AE\"].columns)]\n",
    "if \"TOTAL\" in s.columns and grade_cols:\n",
    "    total_from_grades = s[grade_cols].sum(axis=1, min_count=1)\n",
    "    missing_total = s[\"TOTAL\"].isna()\n",
    "    s.loc[missing_total, \"TOTAL\"] = total_from_grades[missing_total]\n",
    "    print(\"Filled TOTAL from grade sums:\", int(missing_total.sum()))\n",
    "\n",
    "# STUTERATIO: If missing, compute using TOTAL and FTE when both exist.\n",
    "# First, we check that the relationship holds for most records.\n",
    "if \"TOTAL\" in s.columns and \"FTE\" in s.columns and \"STUTERATIO\" in s.columns:\n",
    "    s[\"RATIO_FROM_TOTAL_FTE\"] = s[\"TOTAL\"] / s[\"FTE\"]\n",
    "    s.loc[s[\"FTE\"] == 0, \"RATIO_FROM_TOTAL_FTE\"] = None\n",
    "    temp = s.dropna(subset=[\"STUTERATIO\", \"RATIO_FROM_TOTAL_FTE\"])\n",
    "    temp[\"ABS_DIFF\"] = (temp[\"STUTERATIO\"] - temp[\"RATIO_FROM_TOTAL_FTE\"]).abs()\n",
    "    print(\"mean abs diff =\", round(float(temp[\"ABS_DIFF\"].mean()), 4))\n",
    "    before = s[\"STUTERATIO\"].isna().sum()\n",
    "    s.loc[s[\"STUTERATIO\"].isna(), \"STUTERATIO\"] = s[\"RATIO_FROM_TOTAL_FTE\"]\n",
    "    after = s[\"STUTERATIO\"].isna().sum()\n",
    "    print(\"Filled STUTERATIO values:\", int(before - after))\n",
    "    s = s.drop(columns=[\"RATIO_FROM_TOTAL_FTE\"], errors=\"ignore\")\n",
    "# To verify consistency internally, we compared the STUTERATIO to the computed value TOTAL/FTE. \n",
    "# We calculated the mean absolute difference to measure the avg deviation between the two values. \n",
    "# A small mean absolute difference shows that the ratios are consistent with actual enrollment and teacher counts.\n",
    "\n",
    "# FTE: If missing, compute using TOTAL / STUTERATIO.\n",
    "if \"TOTAL\" in s.columns and \"FTE\" in s.columns and \"STUTERATIO\" in s.columns:\n",
    "    s[\"FTE_FROM_RATIO\"] = s[\"TOTAL\"] / s[\"STUTERATIO\"]\n",
    "    s.loc[s[\"STUTERATIO\"] == 0, \"FTE_FROM_RATIO\"] = None\n",
    "    before = s[\"FTE\"].isna().sum()\n",
    "    s.loc[s[\"FTE\"].isna(), \"FTE\"] = s[\"FTE_FROM_RATIO\"]\n",
    "    after = s[\"FTE\"].isna().sum()\n",
    "    print(\"Filled FTE values:\", int(before - after))\n",
    "    s = s.drop(columns=[\"FTE_FROM_RATIO\"], errors=\"ignore\")\n",
    "\n",
    "# Remaining missing in continuous columns: use group wise median since less sensitive to outliers\n",
    "# Group by SCHOOL_LEVEL and STABR if available because school staffing and enrollment patterns are different depending on level and state.\n",
    "for c in [\"STUTERATIO\", \"FTE\"]:\n",
    "    if c in s.columns:\n",
    "        # If both grouping columns exist, fill by SCHOOL_LEVEL and STABR\n",
    "        if \"SCHOOL_LEVEL\" in s.columns and \"STABR\" in s.columns:\n",
    "            for level in s[\"SCHOOL_LEVEL\"].dropna().unique():\n",
    "                for state in s[\"STABR\"].dropna().unique():\n",
    "                    # rows in this level and this state\n",
    "                    condition = (s[\"SCHOOL_LEVEL\"] == level) & (s[\"STABR\"] == state)\n",
    "                    group_values = s.loc[condition, c]\n",
    "                    # calculate median if the group has at least one proper value\n",
    "                    if group_values.notna().sum() > 0:\n",
    "                        group_median = group_values.median()\n",
    "                        # fill only missing values inside this group\n",
    "                        s.loc[condition & s[c].isna(), c] = group_median\n",
    "        # Otherwise, fill it with overall median\n",
    "        else:\n",
    "            overall_median = s[c].median()\n",
    "            s.loc[s[c].isna(), c] = overall_median\n",
    "# Remaining missing values in continuous variables (STUTERATIO and FTE) were imputed using group-wise median imputation. \n",
    "# Schools were grouped by SCHOOL_LEVEL and STABR because staffing and enrollment differ across different school types and states. \n",
    "# Median was chosen instead of mean to minimize sensitivity to extreme outliers in the enrollment and staffing counters. \n",
    "# This helps to uphold differences in the structure of the dataset but preventing too much data loss from deleting rows. \n",
    "# If grouping variables were unavailable, overall median imputation was used.\n",
    "\n",
    "print(\"\\nMissing counts after continuous imputations:\")\n",
    "print(s[[\"TOTAL\", \"FTE\", \"STUTERATIO\"]].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e163744b-1eaa-445c-8e83-844c0ba72a4f",
   "metadata": {},
   "source": [
    "### 2.4 Imputate Discrete Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4e01aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done discrete repairs. Remaining missing values (top 15):\n",
      "DIRECTCERT    49544\n",
      "HPALM           937\n",
      "HPALF           936\n",
      "AMALM           910\n",
      "AMALF           908\n",
      "HP              890\n",
      "AM              862\n",
      "BLALF           826\n",
      "BLALM           823\n",
      "ASALM           821\n",
      "ASALF           819\n",
      "BL              816\n",
      "TRALM           816\n",
      "TRALF           814\n",
      "TR              813\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Fix postal codes: if LZIP is numeric, leading zeros are lost in python. This converts them back to 5 character string.\n",
    "if \"LZIP\" in s.columns:\n",
    "    s[\"LZIP\"] = s[\"LZIP\"].astype(\"Int64\").astype(str).str.zfill(5)\n",
    "\n",
    "# Address field: if missing, fill with 'Unknown'\n",
    "for c in [\"LSTREET1\", \"PHONE\"]:\n",
    "    if c in s.columns:\n",
    "        s[c] = s[c].fillna(\"Unknown\")\n",
    "# Missing values in categorical variables not included in the analysis such as street address and phone number were replaced \n",
    "# with the placeholder value \"Unknown\". These variables are descriptive identifiers and are not used for analysis. \n",
    "# Replacing missing values prevents needing to delete rows unnecessarily due to empty values and ensures consistency in the dataset.\n",
    "\n",
    "# Free/Reduced lunch fields: these are count fields and can be 0 for schools with no participants.\n",
    "# We used enrollment percentage as a consideration to avoid producing impossible counts.\n",
    "if \"TOTFRL\" in s.columns and \"TOTAL\" in s.columns:\n",
    "    # Create FRL_PCT (only when TOTAL > 0)\n",
    "    s[\"FRL_PCT\"] = s[\"TOTFRL\"] / s[\"TOTAL\"]\n",
    "    s.loc[s[\"TOTAL\"] == 0, \"FRL_PCT\"] = None\n",
    "    # Fill missing FRL_PCT with overall median\n",
    "    frl_median = s[\"FRL_PCT\"].median()\n",
    "    s.loc[s[\"FRL_PCT\"].isna(), \"FRL_PCT\"] = frl_median\n",
    "    # missing TOTFRL using FRL_PCT * TOTAL\n",
    "    s.loc[s[\"TOTFRL\"].isna(), \"TOTFRL\"] = (s[\"FRL_PCT\"] * s[\"TOTAL\"]).round()\n",
    "    # keep TOTFRL within valid range [0, TOTAL]\n",
    "    s.loc[s[\"TOTFRL\"] < 0, \"TOTFRL\"] = 0\n",
    "    s.loc[s[\"TOTFRL\"] > s[\"TOTAL\"], \"TOTFRL\"] = s[\"TOTAL\"]\n",
    "# if FRELCH and REDLCH exist, fill missing by splitting TOTFRL 50/50\n",
    "if \"FRELCH\" in s.columns and \"REDLCH\" in s.columns and \"TOTFRL\" in s.columns:\n",
    "    # If missing, assign half of TOTFRL to free lunch\n",
    "    s.loc[s[\"FRELCH\"].isna(), \"FRELCH\"] = (0.5 * s[\"TOTFRL\"]).round()\n",
    "    # Reduced lunch is whatever is left\n",
    "    s.loc[s[\"REDLCH\"].isna(), \"REDLCH\"] = (s[\"TOTFRL\"] - s[\"FRELCH\"]).round()\n",
    "    # Prevent negatives\n",
    "    s.loc[s[\"REDLCH\"] < 0, \"REDLCH\"] = 0\n",
    "# The Free/Reduced Lunch variables are count fields, so they must be not negative and not greater than total enrollment.\n",
    "# To handle missing values first, we converted the total FRL count into a percentage of enrollment so that any imputed values \n",
    "# would scale properly with school size. Missing percentages were filled using the median to avoid being influenced by extreme values. \n",
    "# Then we rebuilt missing FRL counts using the percentage and total enrollment, rounding to keep whole numbers. \n",
    "# More checks made sure values stayed between 0 and total enrollment. When the free and reduced breakdown was missing,\n",
    "# we used a 50/50 split to maintain consistency. These steps ensured logical modification while keeping as much data as possible.\n",
    "\n",
    "# Ensure counts are non-negative\n",
    "count_cols = [\"TOTAL\", \"TOTFRL\", \"FRELCH\", \"REDLCH\", \"DIRECTCERT\", \"TOTMENROL\", \"TOTFENROL\", \"MEMBER\"]\n",
    "\n",
    "for c in count_cols:\n",
    "    if c in s.columns:\n",
    "        s[c] = pd.to_numeric(s[c], errors=\"coerce\")\n",
    "        s.loc[s[c] < 0, c] = 0\n",
    "\n",
    "print(\"Done discrete repairs. Remaining missing values (top 15):\")\n",
    "print(s.isna().sum().sort_values(ascending=False).head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee10308f-a761-4b05-b2f0-0096e5d57bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling DIRECTCERT\n",
    "## make sure to convert all to numeric\n",
    "s['DIRECTCERT'] = pd.to_numeric(s['DIRECTCERT'], errors='coerce')\n",
    "s['FRELCH'] = pd.to_numeric(s['FRELCH'], errors='coerce')\n",
    "\n",
    "## FRELCH = Free lunch eligible, is high related to DIRECTCERT, so we use it to give an estimation of DIRECTCERT\n",
    "## get the median ratio of \"DIRECTVERT\"/\"FRELCH\"\n",
    "D_ratio = s['DIRECTCERT'] / s['FRELCH']\n",
    "D_median_ratio = D_ratio[\n",
    "    (s['DIRECTCERT'].notna()) & \n",
    "    (s['FRELCH'].notna()) &\n",
    "    (s['FRELCH'] != 0)\n",
    "].median()\n",
    "\n",
    "## give missing value of missing DIRECTCERT only if FRELCH exists\n",
    "D_mask = s['DIRECTCERT'].isna() & s['FRELCH'].notna()\n",
    "s.loc[D_mask, 'DIRECTCERT'] = s.loc[D_mask, 'FRELCH'] * D_median_ratio\n",
    "\n",
    "# Handling CHARTER_TEXT\n",
    "## the value is mostly NO, so check the constant extent\n",
    "#from sklearn.feature_selection import VarianceThreshold\n",
    "#constant_threshold = 0.2\n",
    "#s['CHARTER_TEXT'] = s['CHARTER_TEXT'].map({\n",
    "#    'Yes': 1,\n",
    "#    'No': 0\n",
    "#})\n",
    "#num_df = s.select_dtypes(include='number')\n",
    "#selector = VarianceThreshold(constant_threshold)\n",
    "#selector.fit(num_df)\n",
    "#kept_cols = num_df.columns[selector.get_support()]\n",
    "#constant_cols = num_df.columns[~selector.get_support()]\n",
    "#print(\"Constant columns:\", list(constant_cols))\n",
    "# it's constant so will drop the feature at the step of handling constant feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fab8960d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with all race counts missing: 809\n",
      "Rows where race sum not equal TOTAL (flagged): 5900\n",
      "Rows where male+female != TOTAL: 5978\n",
      "\n",
      "Remaining missing values (top 15):\n",
      "HPALF         61\n",
      "HPALM         60\n",
      "STUTERATIO    49\n",
      "AMALM         41\n",
      "AMALF         36\n",
      "G13            5\n",
      "BLALF          5\n",
      "UG             5\n",
      "AE             5\n",
      "ASALM          5\n",
      "G10            4\n",
      "G12            4\n",
      "G11            4\n",
      "BLALM          4\n",
      "G09            4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cleaning up the races value\n",
    "# Goal: ensure totals are internally consistent and remove/repair impossible records.\n",
    "\n",
    "race_cols = [\"AM\",\"AS\",\"BL\",\"HI\",\"HP\",\"TR\",\"WH\"]\n",
    "race_cols = [c for c in race_cols if c in s.columns]\n",
    "\n",
    "# Convert to numeric\n",
    "for c in race_cols:\n",
    "    s[c] = pd.to_numeric(s[c], errors=\"coerce\")\n",
    "\n",
    "# Race counts: if ALL race columns are missing, ethnicity composition cannot be computed.\n",
    "# Since our problem statement uses ethnicity composition, we drop these rows.\n",
    "all_race_missing = s[race_cols].isna().all(axis=1) if len(race_cols) > 0 else pd.Series(False, index=s.index)\n",
    "print(\"Rows with all race counts missing:\", int(all_race_missing.sum()))\n",
    "s = s.loc[~all_race_missing].copy()\n",
    "\n",
    "# If some race categories are missing but the known categories already sum to TOTAL, then missing categories must be 0.\n",
    "if \"TOTAL\" in s.columns:\n",
    "\n",
    "    race_sum_known = s[race_cols].sum(axis=1, min_count=1)\n",
    "\n",
    "    # Loop through each row\n",
    "    race_na_any = s[race_cols].isna().any(axis=1)\n",
    "    for i in s.index:\n",
    "        if (race_na_any.at[i] and pd.notna(s.at[i, \"TOTAL\"]) and race_sum_known.at[i] == s.at[i, \"TOTAL\"]):\n",
    "            s.loc[i, race_cols] = s.loc[i, race_cols].fillna(0)\n",
    "\n",
    "    # If exactly ONE race category is missing and TOTAL is known, fill the missing one as the remainder.\n",
    "    missing_counts = s[race_cols].isna().sum(axis=1)\n",
    "    one_missing = (missing_counts == 1) & s[\"TOTAL\"].notna()\n",
    "    remainder = s[\"TOTAL\"] - s[race_cols].sum(axis=1, min_count=1)\n",
    "\n",
    "    # Identify which column is missing per row and fill it\n",
    "    for c in race_cols:\n",
    "        mask = one_missing & s[c].isna() & (remainder >= 0)\n",
    "        s.loc[mask, c] = remainder[mask]\n",
    "\n",
    "    # Any remaining negative remainder means race totals exceed TOTAL (inconsistent).\n",
    "    ##remainder_after = s[\"TOTAL\"] - s[race_cols].sum(axis=1, min_count=1)\n",
    "    ##inconsistent_race = remainder_after != 0\n",
    "    \n",
    "    ##s = s.loc[~inconsistent_race].copy()\n",
    "    remainder_after = s[\"TOTAL\"] - s[race_cols].sum(axis=1, min_count=1)\n",
    "    s['TOTAL_RACE_CONS'] = remainder_after == 0  # True if sum equals TOTAL, False otherwise\n",
    "    inconsistent_race = remainder_after != 0\n",
    "    \n",
    "    inconsistent_mask = ~s['TOTAL_RACE_CONS']  # rows where sum != TOTAL\n",
    "    cols_to_fill = s.loc[:, 'AMALM':'WH'].columns  # columns from AMALM to WH\n",
    "    s.loc[inconsistent_mask, cols_to_fill] = s.loc[inconsistent_mask, cols_to_fill].fillna(0)\n",
    "    \n",
    "    print(\"Rows where race sum not equal TOTAL (flagged):\", int(inconsistent_race.sum()))\n",
    "    \n",
    "# Gender totals vs TOTAL: if TOTMENROL + TOTFENROL != TOTAL, we keep as is but flag for awareness.\n",
    "if \"TOTMENROL\" in s.columns and \"TOTFENROL\" in s.columns and \"TOTAL\" in s.columns:\n",
    "    condition = (s[\"TOTMENROL\"].notna() & s[\"TOTFENROL\"].notna() & s[\"TOTAL\"].notna())\n",
    "    # Among those rows, check if male + female does NOT equal TOTAL\n",
    "    inconsistent = s.loc[condition, \"TOTMENROL\"] + s.loc[condition, \"TOTFENROL\"] != s.loc[condition, \"TOTAL\"]\n",
    "    print(\"Rows where male+female != TOTAL:\", int(inconsistent.sum()))\n",
    "    \n",
    "# Final missing snapshot\n",
    "print(\"\\nRemaining missing values (top 15):\")\n",
    "print(s.isna().sum().sort_values(ascending=False).head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "786e4d93-1d5e-4e60-aaf4-e21e3b6c0ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows where grade sum not equal TOTAL (flagged): 5\n"
     ]
    }
   ],
   "source": [
    "grade_cols = s.loc[:, 'PK':'AE'].columns  # columns from PK to AE\n",
    "remainder_after_grades = s[grade_cols].sum(axis=1, min_count=1) - s['TOTAL']  # or whatever your total column is for grades\n",
    "s['TOTAL_GRADE_CONS'] = remainder_after_grades == 0  # True if sum equals TOTAL, False otherwise\n",
    "inconsistent_grade = remainder_after_grades != 0\n",
    "\n",
    "# --- Step 2: Fill NaN with 0 for inconsistent rows only ---\n",
    "inconsistent_grade_mask = ~s['TOTAL_GRADE_CONS']  # rows where sum != TOTAL\n",
    "s.loc[inconsistent_grade_mask, grade_cols] = s.loc[inconsistent_grade_mask, grade_cols].fillna(0)\n",
    "\n",
    "# --- Step 3: Print summary ---\n",
    "print(\"Rows where grade sum not equal TOTAL (flagged):\", int(inconsistent_grade.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08e135f8-0abb-4165-9620-601eb2d3ab14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STUTERATIO    49\n",
      "FTE            2\n",
      "X              0\n",
      "Y              0\n",
      "SURVYEAR       0\n",
      "STABR          0\n",
      "LEAID          0\n",
      "ST_LEAID       0\n",
      "LEA_NAME       0\n",
      "SCH_NAME       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Handling the rest of race values\n",
    "## for race_cols = [\"AM\",\"AS\",\"BL\",\"HI\",\"HP\",\"TR\",\"WH\"], \n",
    "## get the median of the genders of each race and replace the NAN value if the race_cols are not NAN\n",
    "for race in race_cols:\n",
    "    total_col = race\n",
    "    male_col = f\"{race}ALM\"\n",
    "    female_col = f\"{race}ALF\"\n",
    "    \n",
    "    # --- MALE IMPUTATION ---\n",
    "    male_ratio = s[male_col] / s[total_col]\n",
    "    \n",
    "    male_median_ratio = male_ratio[\n",
    "        (s[male_col].notna()) &\n",
    "        (s[total_col].notna()) &\n",
    "        (s[total_col] != 0)\n",
    "    ].median()\n",
    "    \n",
    "    male_mask = s[male_col].isna() & s[total_col].notna()\n",
    "    s.loc[male_mask, male_col] = (s.loc[male_mask, total_col] * male_median_ratio).round().astype(int)\n",
    "    \n",
    "    # --- FEMALE IMPUTATION ---\n",
    "    female_ratio = s[female_col] / s[total_col]\n",
    "    \n",
    "    female_median_ratio = female_ratio[\n",
    "        (s[female_col].notna()) &\n",
    "        (s[total_col].notna()) &\n",
    "        (s[total_col] != 0)\n",
    "    ].median()\n",
    "    \n",
    "    female_mask = s[female_col].isna() & s[total_col].notna()\n",
    "    s.loc[female_mask, female_col] = (s.loc[female_mask, total_col] * female_median_ratio).round().astype(int)\n",
    "    \n",
    "    # --- ADJUST TO ENSURE MALE + FEMALE = TOTAL ---\n",
    "    # For rows where total is known and one or both genders were imputed\n",
    "    adjust_mask = s[total_col].notna() & s[male_col].notna() & s[female_col].notna()\n",
    "    difference = s.loc[adjust_mask, total_col] - (s.loc[adjust_mask, male_col] + s.loc[adjust_mask, female_col])\n",
    "    \n",
    "    # Add/subtract difference to female to balance exactly\n",
    "    s.loc[adjust_mask, female_col] += difference.astype(int)\n",
    "    \n",
    "print(s.isna().sum().sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93b02e16-07fe-45a3-9853-bcd29bb0d45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X           0\n",
      "Y           0\n",
      "OBJECTID    0\n",
      "NCESSCH     0\n",
      "SURVYEAR    0\n",
      "STABR       0\n",
      "LEAID       0\n",
      "ST_LEAID    0\n",
      "LEA_NAME    0\n",
      "SCH_NAME    0\n",
      "LSTREET1    0\n",
      "LCITY       0\n",
      "LSTATE      0\n",
      "LZIP        0\n",
      "PHONE       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PK</th>\n",
       "      <th>KG</th>\n",
       "      <th>G01</th>\n",
       "      <th>G02</th>\n",
       "      <th>G03</th>\n",
       "      <th>G04</th>\n",
       "      <th>G05</th>\n",
       "      <th>G06</th>\n",
       "      <th>G07</th>\n",
       "      <th>G08</th>\n",
       "      <th>G09</th>\n",
       "      <th>G10</th>\n",
       "      <th>G11</th>\n",
       "      <th>G12</th>\n",
       "      <th>G13</th>\n",
       "      <th>UG</th>\n",
       "      <th>AE</th>\n",
       "      <th>TOTMENROL</th>\n",
       "      <th>TOTFENROL</th>\n",
       "      <th>TOTAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PK, KG, G01, G02, G03, G04, G05, G06, G07, G08, G09, G10, G11, G12, G13, UG, AE, TOTMENROL, TOTFENROL, TOTAL]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace the rest NAN STUTERATIO according to TOTAL and FTE\n",
    "## Fill in the rest of the missing FTE\n",
    "\n",
    "## fill in the STUTERATIO\n",
    "mask_fte_known = s['STUTERATIO'].isna() & s['FTE'].notna()\n",
    "s.loc[mask_fte_known, 'STUTERATIO'] = s.loc[mask_fte_known].apply(\n",
    "    lambda row: row['TOTAL'] / row['FTE'] if row['FTE'] != 0 else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Optional: round STUTERATIO\n",
    "s['STUTERATIO'] = s['STUTERATIO'].round(2)\n",
    "\n",
    "# --- Step 2: Fill missing STUTERATIO using group median ---\n",
    "mask_fte_missing = s['STUTERATIO'].isna()\n",
    "group_median_stu = s.groupby(['STABR', 'SCHOOL_LEVEL'])['STUTERATIO'].transform('median')\n",
    "s.loc[mask_fte_missing, 'STUTERATIO'] = s.loc[mask_fte_missing].apply(\n",
    "    lambda row: group_median_stu[row.name] if not pd.isna(group_median_stu[row.name]) else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Optional: round STUTERATIO\n",
    "s['STUTERATIO'] = s['STUTERATIO'].round(2)\n",
    "\n",
    "# --- Step 3: Compute missing FTE from STUTERATIO ---\n",
    "mask_fte_nan = s['FTE'].isna() & s['STUTERATIO'].notna()\n",
    "s.loc[mask_fte_nan, 'FTE'] = s.loc[mask_fte_nan].apply(\n",
    "    lambda row: row['TOTAL'] / row['STUTERATIO'] if row['STUTERATIO'] != 0 else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Optional: round FTE\n",
    "s['FTE'] = s['FTE'].round(2)\n",
    "print(s.isna().sum().sort_values(ascending=False).head(15))\n",
    "s.loc[s[\"G13\"].isna(), \"PK\":\"TOTAL\"]\n",
    "# s.loc[s[\"HP\"].isna(), \"TOTAL\":\"WH\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e5b3e7-91f5-4283-b22e-45822ab3b474",
   "metadata": {},
   "source": [
    "### 2.5 Handling Edge Cases¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40d241e9-d42c-4c71-bbb8-a420f33f86e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STUTERATIO outliers removed: 2916\n"
     ]
    }
   ],
   "source": [
    "# Calculated using box plot bounds derived from IQR\n",
    "q1 = s[\"STUTERATIO\"].quantile(0.25)\n",
    "q3 = s[\"STUTERATIO\"].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "lower = q1 - 1.5 * iqr\n",
    "upper = q3 + 1.5 * iqr\n",
    "\n",
    "outliers = s[\"STUTERATIO\"] > upper\n",
    "print(\"STUTERATIO outliers removed:\", int(outliers.sum()))\n",
    "\n",
    "s.loc[outliers, \"STUTERATIO\"] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cea250-0a98-475e-a627-33d2d6ddf55b",
   "metadata": {},
   "source": [
    "### 2.6 Feature Engineering\n",
    "The features added through the imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b194dade-45fb-47b9-8c7f-84b8e944d12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ethnicity composition as proportions (robust to different school sizes)\n",
    "race_cols = [\"AM\",\"AS\",\"BL\",\"HI\",\"HP\",\"TR\",\"WH\"]\n",
    "race_cols = [c for c in race_cols if c in s.columns]\n",
    "\n",
    "for c in race_cols:\n",
    "    s[c] = pd.to_numeric(s[c], errors=\"coerce\")\n",
    "\n",
    "if \"TOTAL\" in s.columns:\n",
    "    for c in race_cols:\n",
    "        s[f\"{c}_PCT\"] = np.where(s[\"TOTAL\"] > 0, s[c] / s[\"TOTAL\"], np.nan)\n",
    "\n",
    "    # minority share (everything except White)\n",
    "    if \"WH\" in s.columns:\n",
    "        s[\"MINORITY_PCT\"] = 1 - s[\"WH_PCT\"]\n",
    "\n",
    "# School level (ordinal encoding) to support correlation\n",
    "level_map = {\n",
    "    \"Primary\": 1,\n",
    "    \"Middle\": 2,\n",
    "    \"High\": 3,\n",
    "    \"Other\": 0\n",
    "}\n",
    "if \"SCHOOL_LEVEL\" in s.columns:\n",
    "    s[\"SCHOOL_LEVEL_CODE\"] = s[\"SCHOOL_LEVEL\"].map(level_map).fillna(0).astype(int)\n",
    "\n",
    "# Create FRL_PCT\n",
    "if \"FRL_PCT\" not in s.columns and \"TOTFRL\" in s.columns and \"TOTAL\" in s.columns:\n",
    "    s[\"FRL_PCT\"] = s[\"TOTFRL\"] / s[\"TOTAL\"]\n",
    "\n",
    "# Create MINORITY_PCT\n",
    "race_cols = [\"AM\",\"AS\",\"BL\",\"HI\",\"HP\",\"TR\",\"WH\"]\n",
    "race_cols = [c for c in race_cols if c in s.columns]\n",
    "\n",
    "if \"MINORITY_PCT\" not in s.columns and \"WH\" in s.columns and \"TOTAL\" in s.columns:\n",
    "    s[\"MINORITY_PCT\"] = 1 - (s[\"WH\"] / s[\"TOTAL\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8044204f-9b9e-4fc9-b440-f5f241045095",
   "metadata": {},
   "source": [
    "### 2.7 Dropping Constant Features and Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2f03383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant columns: []\n",
      "Exact duplicate rows removed: 0\n",
      "STUTERATIO    2916\n",
      "X                0\n",
      "OBJECTID         0\n",
      "Y                0\n",
      "STABR            0\n",
      "ST_LEAID         0\n",
      "LEA_NAME         0\n",
      "SURVYEAR         0\n",
      "SCH_NAME         0\n",
      "LSTREET1         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "# Drop fully-constant columns providing no information for model\n",
    "constant_threshold = 0.3\n",
    "num_df = s.select_dtypes(include='number')\n",
    "selector = VarianceThreshold(constant_threshold)\n",
    "selector.fit(num_df)\n",
    "kept_cols = num_df.columns[selector.get_support()]\n",
    "constant_cols = num_df.columns[~selector.get_support()]\n",
    "print(\"Constant columns:\", list(constant_cols))\n",
    "s = s.drop(columns=constant_cols)\n",
    "\n",
    "# >= 99.5% of rows share the same value\n",
    "#quasi_constant_cols = []\n",
    "#for col in s.columns:\n",
    "#    top_freq = s[col].value_counts(dropna=False, normalize=True).iloc[0]\n",
    "    # if top_freq >= 0.995:\n",
    "    #     quasi_constant_cols.append(col)\n",
    "\n",
    "# print(\">=99.5% same:\", quasi_constant_cols)\n",
    "\n",
    "# Remove duplicate records (exact duplicates or duplicate school IDs)\n",
    "before = s.shape[0]\n",
    "s = s.drop_duplicates()\n",
    "after = s.shape[0]\n",
    "print(f\"Exact duplicate rows removed: {before-after}\")\n",
    "\n",
    "if \"NCESSCH\" in s.columns:\n",
    "    before = s.shape[0]\n",
    "    s = s.drop_duplicates(subset=[\"NCESSCH\"])\n",
    "    after = s.shape[0]\n",
    "    print(f\"Duplicate NCESSCH rows removed: {before-after}\")\n",
    "print(s.isna().sum().sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b2ed7e-b1c8-4e43-a379-91ce804838c6",
   "metadata": {},
   "source": [
    "### 2.8 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a88791b3-cb82-4506-93c6-9369341354fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "#Using Pearson Correlation\n",
    "\n",
    "s_corr = s.copy()\n",
    "if \"STUTERATIO\" in s_corr.columns:\n",
    "    s_corr = s_corr.drop(columns=[\"STUTERATIO\"])\n",
    "    \n",
    "num_df = s_corr.select_dtypes(include='number')\n",
    "\n",
    "# Compute correlation\n",
    "# cor = num_df.corr()\n",
    "\n",
    "# # Plot heatmap\n",
    "# plt.figure(figsize=(8,6))\n",
    "# sns.heatmap(cor, annot=True, cmap=plt.cm.CMRmap_r)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "                colname = corr_matrix.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    return col_corr\n",
    "corr_features = correlation(num_df, 0.7)\n",
    "corr_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e809c794-5d45-4398-9931-16ef6796bfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.drop(corr_features,axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8986a41d-dcc4-47b7-a92b-cc912f84b787",
   "metadata": {},
   "source": [
    "### 2.9 Data Shape After Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "744aa415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after cleaning: (98910, 40)\n",
      "Total missing values remaining: 2916\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape after cleaning:\", s.shape)\n",
    "print(\"Total missing values remaining:\", int(s.isna().sum().sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65894832-e92a-4da2-a3a2-ade8d7a818ad",
   "metadata": {},
   "source": [
    "## Step 3: Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "52926fb3-8ad2-4ae5-94a7-b1dcaa52e8c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'TOTAL'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\indexes\\base.py:3641\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3640\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3641\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3642\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:168\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:197\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7668\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7676\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'TOTAL'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m plt.figure()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m plt.hist(\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTOTAL\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.dropna(), bins=\u001b[32m30\u001b[39m)\n\u001b[32m      5\u001b[39m plt.title(\u001b[33m\"\u001b[39m\u001b[33mDistribution of TOTAL\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m plt.xlabel(\u001b[33m\"\u001b[39m\u001b[33mTOTAL\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\frame.py:4378\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4376\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4377\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4378\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4379\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4380\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\indexes\\base.py:3648\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3643\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3644\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3645\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3646\u001b[39m     ):\n\u001b[32m   3647\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3648\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3649\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3650\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3651\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3652\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3653\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'TOTAL'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(s[\"TOTAL\"].dropna(), bins=30)\n",
    "plt.title(\"Distribution of TOTAL\")\n",
    "plt.xlabel(\"TOTAL\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "882224f8-4749-4d70-ae31-cc386fa5d0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in key_features:\n",
    "    if col in s.columns:\n",
    "        plt.figure()\n",
    "        plt.boxplot(s[col].dropna())\n",
    "        plt.title(f\"Boxplot of {col}\")\n",
    "        plt.ylabel(col)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "298e840c-3fa7-408e-95a3-67729bc1db9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"MINORITY_PCT\" in s.columns and \"FTE\" in s.columns:\n",
    "    plt.figure()\n",
    "    plt.scatter(s[\"MINORITY_PCT\"], s[\"FTE\"], alpha=0.3)\n",
    "    plt.title(\"FTE vs MINORITY_PCT\")\n",
    "    plt.xlabel(\"MINORITY_PCT\")\n",
    "    plt.ylabel(\"FTE\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "983ee9eb-7186-4419-9c81-ba5130eb91ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"FRL_PCT\" in s.columns and \"TOTAL\" in s.columns:\n",
    "    plt.figure()\n",
    "    plt.scatter(s[\"FRL_PCT\"], s[\"TOTAL\"], alpha=0.3)\n",
    "    plt.title(\"TOTAL vs FRL_PCT\")\n",
    "    plt.xlabel(\"FRL_PCT\")\n",
    "    plt.ylabel(\"TOTAL\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb0d7b1-d112-4e49-ae54-317cf52848c1",
   "metadata": {},
   "source": [
    "## Step 3: Normalization and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f294a441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Transformation (log1p) for heavy-tailed count features to reduce skew\n",
    "\n",
    "# Standardization (z-score) for continuous features used in modeling\n",
    "\n",
    "# Select a few representative count features\n",
    "count_features = [c for c in [\"TOTAL\",\"FTE\",\"TOTFRL\"] if c in s.columns]\n",
    "for c in count_features:\n",
    "    s[f\"LOG1P_{c}\"] = np.log1p(s[c])\n",
    "\n",
    "# Standardize continuous features\n",
    "cont_features = [c for c in [\"STUTERATIO\",\"FRL_PCT\",\"MINORITY_PCT\",\"TOTAL\",\"FTE\"] if c in s.columns]\n",
    "for c in cont_features:\n",
    "    mean = s[c].mean()\n",
    "    std = s[c].std()\n",
    "    s[f\"Z_{c}\"] = (s[c] - mean) / std\n",
    "\n",
    "# Correlation analysis: which engineered variables correlate with STUTERATIO?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c2c7ae",
   "metadata": {},
   "source": [
    "### 3.1 Export Cleaned Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d11da9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.to_csv(\"Deliverable2_cleaned.csv\", index=False)\n",
    "print(\"Saved Deliverable2_cleaned_final.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
